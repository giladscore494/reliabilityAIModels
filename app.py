# -*- coding: utf-8 -*-
# ===========================================================
# ğŸ‡®ğŸ‡± Car Reliability Analyzer v3.1.0
# Sheets + Minimal Connect Banner + Smart 45d Cache + No Auth
# ×ª×¦×•×’×ª ×ª×•×¦××” ××”×××’×¨ ×–×”×” ×œ×¤×•×¨××˜ ×©×œ ×ª×©×•×‘×ª ×”××•×“×œ
# ===========================================================

import json, re, datetime, difflib, traceback
import pandas as pd
import streamlit as st
from json_repair import repair_json
import google.generativeai as genai

# ---------------- UI ----------------
st.set_page_config(page_title="ğŸš— Car Reliability Analyzer (Sheets)", page_icon="ğŸ”§", layout="centered")
st.title("ğŸš— Car Reliability Analyzer â€“ ×‘×“×™×§×ª ×××™× ×•×ª ×¨×›×‘ ×‘×™×©×¨××œ (Sheets)")

# ---------------- Secrets ----------------
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
GOOGLE_SHEET_ID = st.secrets.get("GOOGLE_SHEET_ID", "")
GOOGLE_SERVICE_ACCOUNT_JSON = st.secrets.get("GOOGLE_SERVICE_ACCOUNT_JSON", "")

# ---------------- Model ----------------
if not GEMINI_API_KEY:
    st.error("âš ï¸ ×—×¡×¨ GEMINI_API_KEY ×‘-Secrets.")
    st.stop()
genai.configure(api_key=GEMINI_API_KEY)
llm = genai.GenerativeModel("gemini-2.5-flash")

# ---------------- Models dictionary ----------------
# × ×“×¨×© ×‘×§×•×‘×¥ × ×¤×¨×“ ××¦×œ×š ×›×¤×™ ×©×¢×‘×“ ×¢×“ ×¢×›×©×™×•
from car_models_dict import israeli_car_market_full_compilation

# ---------------- Helpers ----------------
def normalize_text(s: str) -> str:
    if s is None:
        return ""
    s = re.sub(r"\(.*?\)", " ", str(s))
    s = re.sub(r"[^0-9A-Za-z×-×ª]+", " ", s)
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s

def similarity(a: str, b: str) -> float:
    return difflib.SequenceMatcher(None, normalize_text(a), normalize_text(b)).ratio()

def parse_year_range_from_model_label(model_label: str):
    m = re.search(r"\((\d{4})\s*-\s*(\d{4})", str(model_label))
    return (int(m.group(1)), int(m.group(2))) if m else (None, None)

def build_prompt(make, model, year, fuel_type, transmission):
    return f"""
××ª×” ××•××—×” ×œ×××™× ×•×ª ×¨×›×‘×™× ×‘×™×©×¨××œ ×¢× ×’×™×©×” ×œ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™.
×—×•×‘×” ×œ×‘×¦×¢ ×—×™×¤×•×© ×¢×“×›× ×™ ×‘×¢×‘×¨×™×ª ×•×‘×× ×’×œ×™×ª ×××§×•×¨×•×ª ×××™× ×™× ×‘×œ×‘×“.
×”×—×–×¨ JSON ×‘×œ×‘×“ ×¢× ×”××¤×ª×—/×¢×¨×š ×”×‘××™×:

{{
  "search_performed": true ××• false,
  "base_score": ××¡×¤×¨ ×‘×™×Ÿ 0 ×œ-100,
  "common_issues": [×ª×§×œ×•×ª × ×¤×•×¦×•×ª ×‘×¢×‘×¨×™×ª],
  "avg_repair_cost_ILS": ××¡×¤×¨ ×××•×¦×¢,
  "issues_with_costs": [
    {{"issue": "×©× ×”×ª×§×œ×” ×‘×¢×‘×¨×™×ª", "avg_cost_ILS": ××¡×¤×¨, "source": "××§×•×¨"}}
  ],
  "reliability_summary": "×¡×™×›×•× ×‘×¢×‘×¨×™×ª ×¢×œ ×¨××ª ×”×××™× ×•×ª",
  "sources": ["×¨×©×™××ª ××ª×¨×™×"]
}}

ğŸ§® ××©×§×œ×•×ª ×œ×¦×™×•×Ÿ ×××™× ×•×ª:
- ×× ×•×¢/×’×™×¨ â€“ 35%
- ×—×©××œ ×•××œ×§×˜×¨×•× ×™×§×” â€“ 20%
- ××ª×œ×™× ×•×‘×œ××™× â€“ 10%
- ×¢×œ×•×ª ×ª×—×–×•×§×” â€“ 15%
- ×©×‘×™×¢×•×ª ×¨×¦×•×Ÿ â€“ 15%
- ×¨×™×§×•×œ×™× â€“ 5%

×¨×›×‘: {make} {model} {int(year)}
×¡×•×’ ×“×œ×§: {fuel_type}
×ª×™×‘×ª ×”×™×œ×•×›×™×: {transmission}
×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“.
""".strip()

def safe_json_parse(value):
    """×× ×¡×” ×œ×¤×¢× ×— ××—×¨×•×–×ª JSON ××• ×œ×”×—×–×™×¨ ×¢×¨×š ×¨×™×§ ×‘×˜×•×—."""
    if value is None:
        return None
    if isinstance(value, (list, dict)):
        return value
    s = str(value).strip()
    if not s:
        return None
    try:
        return json.loads(s)
    except Exception:
        try:
            fixed = repair_json(s)
            return json.loads(fixed)
        except Exception:
            return None

# ---------------- Minimal Connectivity (Backend) ----------------
def connect_sheet():
    """×× ×¡×” ×œ×”×ª×—×‘×¨ ×œ-Google Sheets ×•××—×–×™×¨ (ws, status_text, ok_bool)."""
    if not (GOOGLE_SHEET_ID and GOOGLE_SERVICE_ACCOUNT_JSON):
        return None, "âŒ ×”×ª×—×‘×¨×•×ª ×œ×××’×¨ × ×›×©×œ×” (×—×¡×¨×™× Secrets).", False
    try:
        svc = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
        if "\\n" in svc.get("private_key",""):
            svc["private_key"] = svc["private_key"].replace("\\n","\n")
        from google.oauth2.service_account import Credentials
        import gspread
        credentials = Credentials.from_service_account_info(
            svc,
            scopes=[
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive"
            ],
        )
        gc = gspread.authorize(credentials)
        sh = gc.open_by_key(GOOGLE_SHEET_ID)
        ws = sh.sheet1
        # ×•×“× ×›×•×ª×¨×•×ª (×”×¨×—×‘× ×• ×¢××•×“×•×ª ×›×“×™ ×œ×©××•×¨ ×ª×¦×•×’×” ××œ××”)
        headers = [
            "date","user_id","make","model","year","fuel","transmission",
            "base_score","avg_cost","issues","search_performed",
            "reliability_summary","issues_with_costs","sources"
        ]
        current = ws.row_values(1)
        if [c.lower() for c in current] != headers:
            ws.update("A1",[headers], value_input_option="USER_ENTERED")
        return ws, "âœ… ×”×ª×—×‘×¨×•×ª ×œ×××’×¨: ×”×¦×œ×™×—×”", True
    except Exception:
        return None, "âŒ ×”×ª×—×‘×¨×•×ª ×œ×××’×¨ × ×›×©×œ×” (×‘×“×•×§ ×”×¨×©××•×ª/×©×™×ª×•×£ ×œ-service account).", False

ws, conn_msg, conn_ok = connect_sheet()
st.caption(f"ğŸ”Œ {conn_msg}")
if not conn_ok:
    st.stop()

# ---------------- Sheet I/O ----------------
def sheet_to_df() -> pd.DataFrame:
    try:
        recs = ws.get_all_records()
    except Exception as e:
        st.error("âŒ ×›×©×œ ×‘×§×¨×™××ª × ×ª×•× ×™× ××”×××’×¨ (Google Sheets)")
        st.code(repr(e))
        return pd.DataFrame(columns=[
            "date","user_id","make","model","year","fuel","transmission",
            "base_score","avg_cost","issues","search_performed",
            "reliability_summary","issues_with_costs","sources"
        ])
    return pd.DataFrame(recs) if recs else pd.DataFrame(columns=[
        "date","user_id","make","model","year","fuel","transmission",
        "base_score","avg_cost","issues","search_performed",
        "reliability_summary","issues_with_costs","sources"
    ])

def append_row_to_sheet(row_dict: dict):
    order = ["date","user_id","make","model","year","fuel","transmission",
             "base_score","avg_cost","issues","search_performed",
             "reliability_summary","issues_with_costs","sources"]
    row = [row_dict.get(k,"") for k in order]
    try:
        ws.append_row(row, value_input_option="USER_ENTERED")
    except Exception as e:
        st.error("âŒ ×›×©×œ ×‘×›×ª×™×‘×” ×œ×××’×¨")
        st.code(repr(e))

# ---------------- Limits ----------------
GLOBAL_DAILY_LIMIT = 1000  # ××’×‘×œ×ª ××¢×¨×›×ª ×‘×œ×‘×“

def within_daily_global_limit(df: pd.DataFrame, limit=GLOBAL_DAILY_LIMIT):
    today = datetime.date.today().isoformat()
    cnt = len(df[df.get("date","").astype(str) == today]) if not df.empty and "date" in df.columns else 0
    return (cnt < limit, cnt)

# ---------------- Smart Cache (45d, Hardened) ----------------
def get_cached_from_sheet(make: str, model: str, year: int, max_days=45):
    """
    ×§×©×™×—: ×× ×§×™×™××ª ××¤×™×œ×• ×ª×•×¦××” ××—×ª ×-â‰¤45 ×™×•× â†’ × ×—×–×™×¨ ××™×™×“ (×œ×œ× Gemini).
    ×× 3+ ×ª×•×¦××•×ª â†’ × ×—×–×™×¨ ×××•×¦×¢ ×™×¦×™×‘ ×œ×‘×¡×™×¡ (base_cost/avg_cost) + ×ª×¦×•×’×ª issues ××—×¨×•× ×•×ª.
    ×”×”×ª×××”: ×©× ×ª×•×Ÿ 1:1, similarity ×œ×™×¦×¨×Ÿ/×“×’×: ×§×•×“× 0.97 ×•××– 0.93 ×¢× normalize.
    """
    df = sheet_to_df()
    if df.empty:
        return None, df

    # ×˜×™×¤×•×¡×™× ×•×ª××¨×™×š
    try:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df["year"] = pd.to_numeric(df["year"], errors="coerce").astype("Int64")
    except Exception:
        pass

    cutoff = pd.Timestamp.now() - pd.Timedelta(days=max_days)
    recent = df[df["date"] >= cutoff] if "date" in df.columns else df

    mk = normalize_text(make)
    md = normalize_text(model)

    hits = pd.DataFrame()
    for th in (0.97, 0.93):
        cand = recent[
            (recent["year"].astype("Int64") == int(year)) &
            (recent["make"].apply(lambda x: similarity(x, mk) >= th)) &
            (recent["model"].apply(lambda x: similarity(x, md) >= th))
        ]
        if not cand.empty:
            hits = cand.sort_values("date")
            break

    if hits.empty:
        return None, df

    # 3+ â†’ ×××•×¦×¢ ×™×¦×™×‘ ×œ×‘×¡×™×¡; ×ª×¦×•×’×” ×–×”×” ×›×›×œ ×”× ×™×ª×Ÿ
    if len(hits) >= 3:
        base_score_series = pd.to_numeric(hits["base_score"], errors="coerce").dropna()
        avg_cost_series  = pd.to_numeric(hits["avg_cost"], errors="coerce").dropna()
        issues_tail = "; ".join([str(x) for x in hits["issues"].astype(str).tail(3)])
        # ×¢×œ×•×™×•×ª ××¤×•×¨×˜×•×ª: ××™×Ÿ ×”×™×’×™×•×Ÿ ×××•×¦×¢; × ×¦×™×’ ×¨×§ ×× ×œ×©×•×¨×” ×”××—×¨×•× ×” ×™×©
        last_row = hits.iloc[-1].to_dict()
        issues_with_costs = safe_json_parse(last_row.get("issues_with_costs"))
        reliability_summary = last_row.get("reliability_summary") or ""
        return {
            "is_aggregate": True,
            "count": int(len(hits)),
            "base_score": int(round(base_score_series.mean())) if not base_score_series.empty else None,
            "avg_cost": int(round(avg_cost_series.mean())) if not avg_cost_series.empty else None,
            "issues": issues_tail,  # ××—×¨×•×–×ª; × ×¤×¨×§ ×œ×”×¦×’×”
            "issues_with_costs": issues_with_costs if isinstance(issues_with_costs, list) else [],
            "reliability_summary": reliability_summary,
            "search_performed": "true (history aggregate)",
            "last_date": str(hits.iloc[-1]["date"].date()) if not hits.empty else None,
            "sources": last_row.get("sources","")
        }, df

    # ××—×¨×ª â†’ ×ª×—×–×™×¨ ××ª ×”×—×“×©×” ×‘×™×•×ª×¨ 1:1
    row = hits.iloc[-1].to_dict()
    row["is_aggregate"] = False
    row["count"] = int(len(hits))
    # ×•×•×“× ×¤×¢× ×•×— ×”×©×“×•×ª ×”××•×¨×›×‘×™×
    row["issues_with_costs"] = safe_json_parse(row.get("issues_with_costs")) or []
    row["reliability_summary"] = row.get("reliability_summary") or ""
    row["last_date"] = str(hits.iloc[-1]["date"].date())
    return row, df

# ---------------- UI Selection ----------------
st.markdown("### ğŸ” ×‘×—×™×¨×ª ×™×¦×¨×Ÿ, ×“×’× ×•×©× ×ª×•×Ÿ")
make_list = sorted(israeli_car_market_full_compilation.keys())
make_choice = st.selectbox("×‘×—×¨ ×™×¦×¨×Ÿ:", ["×‘×—×¨..."] + make_list, index=0)
make_input  = st.text_input("××• ×”×–×Ÿ ×©× ×™×¦×¨×Ÿ ×™×“× ×™×ª:")

selected_make = make_choice if make_choice != "×‘×—×¨..." else make_input.strip()
selected_make = selected_make or ""

selected_model = ""
year_range = None

if selected_make in israeli_car_market_full_compilation:
    models = israeli_car_market_full_compilation[selected_make]
    model_choice = st.selectbox(f"×“×’× ×©×œ {selected_make}:", ["×‘×—×¨ ×“×’×..."] + models, index=0)
    model_input  = st.text_input("××• ×”×–×Ÿ ×“×’× ×™×“× ×™×ª:")
    selected_model = model_choice if model_choice != "×‘×—×¨ ×“×’×..." else model_input.strip()
    if selected_model:
        yr_start, yr_end = parse_year_range_from_model_label(selected_model)
        if yr_start and yr_end:
            year_range = (yr_start, yr_end)
else:
    if selected_make:
        selected_model = st.text_input("×©× ×“×’×:")

if year_range:
    year = st.number_input(f"×©× ×ª ×™×™×¦×•×¨ ({year_range[0]}â€“{year_range[1]}):",
                           min_value=year_range[0], max_value=year_range[1], step=1)
else:
    year = st.number_input("×©× ×ª ×™×™×¦×•×¨:", min_value=1960, max_value=2025, step=1)

col1, col2 = st.columns(2)
with col1:
    fuel_type = st.selectbox("×¡×•×’ ×“×œ×§:", ["×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™", "×—×©××œ×™", "××—×¨"])
with col2:
    transmission = st.selectbox("×ª×™×‘×ª ×”×™×œ×•×›×™×:", ["××•×˜×•××˜×™×ª", "×™×“× ×™×ª"])

st.markdown("---")

# ---------------- Render helpers ----------------
def render_like_model(base_score, summary, issues_list, detailed_costs_list, source_tag):
    """××¦×™×’ ×ª×•×¦××” ×‘×“×™×•×§ ×›××• ×¤×•×¨××˜ ×”××•×“×œ."""
    st.subheader(f"×¦×™×•×Ÿ ×××™× ×•×ª ×›×•×œ×œ: {int(base_score)}/100")
    if summary:
        st.write(summary)
    if issues_list:
        st.markdown("**ğŸ”§ ×ª×§×œ×•×ª × ×¤×•×¦×•×ª:**")
        for i in issues_list:
            st.markdown(f"- {i}")
    if detailed_costs_list:
        st.markdown("**ğŸ’° ×¢×œ×•×™×•×ª ×ª×™×§×•×Ÿ (××™× ×“×™×§×˜×™×‘×™):**")
        for item in detailed_costs_list:
            issue = (item.get("issue","") if isinstance(item, dict) else "")
            cost  = (item.get("avg_cost_ILS", 0) if isinstance(item, dict) else 0)
            src   = (item.get("source","") if isinstance(item, dict) else "")
            st.markdown(f"- {issue}: ×›-{int(cost)} â‚ª (××§×•×¨: {src})")
    if source_tag:
        st.caption(source_tag)

def explode_issues(issues_field):
    """××§×‘×œ 'issues' ×©×¢×œ×•×œ ×œ×”×™×•×ª ××—×¨×•×–×ª ××•×¤×¨×“×ª ×‘× ×§×•×“×”-×¤×¡×™×§ ××• ×¨×©×™××”; ××—×–×™×¨ ×¨×©×™××”."""
    if issues_field is None:
        return []
    if isinstance(issues_field, list):
        return [str(x).strip() for x in issues_field if str(x).strip()]
    s = str(issues_field)
    if ";" in s:
        return [x.strip() for x in s.split(";") if x.strip()]
    if "," in s:
        return [x.strip() for x in s.split(",") if x.strip()]
    return [s] if s.strip() else []

# ---------------- Run Button ----------------
if st.button("×‘×“×•×§ ×××™× ×•×ª"):
    if not selected_make or not selected_model:
        st.error("×™×© ×œ×”×–×™×Ÿ ×©× ×™×¦×¨×Ÿ ×•×“×’× ×ª×§×™× ×™×.")
        st.stop()

    # ××’×‘×œ×ª ××¢×¨×›×ª ×™×•××™×ª
    df_all = sheet_to_df()
    ok_global, total_global = within_daily_global_limit(df_all, limit=GLOBAL_DAILY_LIMIT)
    if not ok_global:
        st.error(f"âŒ ×—×¦×™×ª× ××ª ××’×‘×œ×ª {GLOBAL_DAILY_LIMIT} ×”×‘×“×™×§×•×ª ×”×™×•××™×•×ª (×‘×•×¦×¢×• {total_global}). × ×¡×• ××—×¨.")
        st.stop()

    # ===== Cache first (×§×©×™×—): ×× ×™×© ××¤×™×œ×• ××—×ª ×‘-â‰¤45 ×™×•× â†’ ×œ×”×¦×™×’ ××™×™×“ ×‘×¤×•×¨××˜ ×–×”×” ×œ××•×“×œ =====
    cached_row, _ = get_cached_from_sheet(selected_make, selected_model, int(year), max_days=45)
    if cached_row:
        is_agg = cached_row.get("is_aggregate", False)
        base_score = cached_row.get("base_score", None)
        avg_cost   = cached_row.get("avg_cost", None)
        issues_raw = cached_row.get("issues", [])
        issues_list = explode_issues(issues_raw)
        detailed_costs = cached_row.get("issues_with_costs", []) or []
        summary = cached_row.get("reliability_summary", "") or ""
        last_date = cached_row.get("last_date", "")
        source_tag = f"âœ… ××§×•×¨: × ×ª×•×Ÿ ×§×™×™× ××”×××’×¨ (× ×‘×“×§: {last_date}). ×œ× ×‘×•×¦×¢×” ×¤× ×™×™×” ×œ××•×“×œ."

        if base_score is None and not issues_list and not detailed_costs and not summary:
            st.warning("ğŸš§ ××™×Ÿ ×¡×™×›×•×/×ª×§×œ×•×ª ××”×××’×¨ ×¢×‘×•×¨ ×”×¨×›×‘ ×”×–×”. ××•××œ×¥ ×œ×‘×¦×¢ ×‘×“×™×§×” ×¢×“×›× ×™×ª.")
            st.stop()

        # ×ª×¦×•×’×” ×–×”×” ×œ××•×“×œ
        if base_score is not None:
            render_like_model(base_score, summary, issues_list, detailed_costs, source_tag)
            # ×”×¦×’×ª ×××•×¦×¢ ×¢×œ×•×ª ×× ×§×™×™×
            if avg_cost not in [None, "", "nan"]:
                st.info(f"×¢×œ×•×ª ×ª×—×–×•×§×” ×××•×¦×¢×ª: ×›-{int(float(avg_cost))} â‚ª")
            st.stop()
        else:
            # ××™×Ÿ base_score ×©××•×¨ â€“ ××™×Ÿ ×¤× ×™×™×” ×œ××•×“×œ ×œ×¤×™ ×‘×§×©×ª×š
            st.warning("ğŸš§ ××™×Ÿ ×¦×™×•×Ÿ ×©××•×¨ ×‘×××’×¨ ×¢×‘×•×¨ ×”×¨×›×‘ ×”×–×”. ××•××œ×¥ ×œ×‘×¦×¢ ×‘×“×™×§×” ×¢×“×›× ×™×ª.")
            st.stop()

    # ===== No cache â†’ call Gemini =====
    prompt = build_prompt(selected_make, selected_model, int(year), fuel_type, transmission)
    try:
        with st.spinner("ğŸŒ ××‘×¦×¢ ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™ ×•××—×©×‘ ×¦×™×•×Ÿ..."):
            resp = llm.generate_content(prompt)
            raw = (getattr(resp, "text", "") or "").strip()
            m = re.search(r"\{.*\}", raw, re.DOTALL)
            parsed = json.loads(m.group()) if m else json.loads(repair_json(raw))
    except Exception as e:
        st.error("×©×’×™××” ×‘×¢×™×‘×•×“ ×ª×©×•×‘×ª ×”××•×“×œ:")
        st.code(repr(e))
        st.code(traceback.format_exc())
        st.stop()

    base_score = int(parsed.get("base_score", 0) or 0)
    issues = parsed.get("common_issues", [])
    avg_cost = parsed.get("avg_repair_cost_ILS", 0)
    summary = parsed.get("reliability_summary", "××™×Ÿ ××™×“×¢.")
    detailed_costs = parsed.get("issues_with_costs", [])
    sources = parsed.get("sources", [])

    # ×ª×¦×•×’×” ×–×”×”
    render_like_model(
        base_score,
        summary,
        issues,
        detailed_costs,
        "ğŸŒ ××§×•×¨: ×—×™×¤×•×© ×‘×–××Ÿ ×××ª (Gemini)"
    )
    if avg_cost not in [None, "", "nan"]:
        st.info(f"×¢×œ×•×ª ×ª×—×–×•×§×” ×××•×¦×¢×ª: ×›-{int(float(avg_cost))} â‚ª")

    # ×©××™×¨×” ××œ××” ×œ×××’×¨ (× ×•×¨××œ×™×–×¦×™×” ×œ×©×“×•×ª ×”×˜×§×¡×˜)
    try:
        issues_str = "; ".join(issues) if isinstance(issues, list) else str(issues)
        issues_with_costs_str = json.dumps(detailed_costs, ensure_ascii=False)
        sources_str = json.dumps(sources, ensure_ascii=False) if isinstance(sources, list) else str(sources)
    except Exception:
        issues_str = str(issues)
        issues_with_costs_str = str(detailed_costs)
        sources_str = str(sources)

    append_row_to_sheet({
        "date": datetime.date.today().isoformat(),
        "user_id": "anonymous",
        "make": normalize_text(selected_make),
        "model": normalize_text(selected_model),
        "year": int(year),
        "fuel": fuel_type,
        "transmission": transmission,
        "base_score": base_score,
        "avg_cost": avg_cost,
        "issues": issues_str,
        "search_performed": "true",
        "reliability_summary": summary,
        "issues_with_costs": issues_with_costs_str,
        "sources": sources_str
    })
    st.caption("ğŸ’¾ × ×©××¨ ×œ×××’×¨ ×‘×”×¦×œ×—×”.")