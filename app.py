# -*- coding: utf-8 -*-
# ===========================================================
# ğŸ‡®ğŸ‡± Car Reliability Analyzer v2.3.0 (Sheets Only + Always-On Debug)
# ===========================================================
# ××” ×›×œ×•×œ:
# - ×—×™×‘×•×¨ ×œ×’×•×’×œ ×©×™×˜×¡ ×“×¨×š Service Account (××”-Secrets)
# - ×“×™×‘××’ ×—×™×‘×•×¨ ××¤×•×¨×˜ ×©××•×¦×’ ×ª××™×“ ×¢×œ ×”××¡×š (×©×œ×‘×™×, ×›×©×œ, ×•×”×¡×‘×¨ ××™×š ×œ×ª×§×Ÿ)
# - ×‘×—×™×¨×ª ×™×¦×¨×Ÿ/×“×’×/×©× ×ª×•×Ÿ ×¢× ×˜×•×•×— ××”××™×œ×•×Ÿ + ×¡×•×’ ×“×œ×§ + ×ª×™×‘×ª ×”×™×œ×•×›×™×
# - Cache ×‘×©×™×˜×¡ ×œ-45 ×™×•×:
#     * ×× ×™×© ××¤×™×œ×• ×ª×•×¦××” ××—×ª ×¢×“×›× ×™×ª â†’ ××—×–×™×¨×™× ×™×©×¨, ×‘×œ×™ ××•×“×œ
#     * ×× ×™×© 3+ ×ª×•×¦××•×ª ×¢×“×›× ×™×•×ª â†’ ××¦×™×’×™× ×××•×¦×¢ (×™×¦×™×‘×•×ª)
# - ××’×‘×œ×•×ª ×©×™××•×©:
#     * ×’×œ×•×‘×œ×™×ª: 1000 ×œ×™×•×
#     * ×œ××©×ª××©: ××‘×•×˜×œ (anonymous, ×œ×¤×™ ×‘×—×™×¨×ª×š "0")
# - ××•×“×œ: gemini-2.5-flash
# ===========================================================

import json, re, datetime, difflib, traceback
import pandas as pd
import streamlit as st
from json_repair import repair_json
import google.generativeai as genai

# ====== ×¢×™×¦×•×‘/×”×’×“×¨×•×ª ×‘×¡×™×¡ ======
st.set_page_config(page_title="ğŸš— Car Reliability Analyzer (Sheets)", page_icon="ğŸ”§", layout="centered")
st.title("ğŸš— Car Reliability Analyzer â€“ ×‘×“×™×§×ª ×××™× ×•×ª ×¨×›×‘ ×‘×™×©×¨××œ (Sheets)")

# ====== ×˜×¢×™× ×ª Secrets ======
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
GOOGLE_SHEET_ID = st.secrets.get("GOOGLE_SHEET_ID")
GOOGLE_SERVICE_ACCOUNT_JSON = st.secrets.get("GOOGLE_SERVICE_ACCOUNT_JSON")  # JSON ×›××—×¨×•×–×ª

# ====== ×§×•× ×¤×™×’ ××•×“×œ ======
if not GEMINI_API_KEY:
    st.error("âš ï¸ ×—×¡×¨ GEMINI_API_KEY ×‘-Secrets.")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
llm = genai.GenerativeModel("gemini-2.5-flash")

# ====== ××™×œ×•×Ÿ ×“×’××™× ======
from car_models_dict import israeli_car_market_full_compilation

# ====== ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ======
def normalize_text(s: str) -> str:
    return re.sub(r"\s+", " ", re.sub(r"\(.*?\)", "", str(s))).strip().lower()

def similar(a: str, b: str) -> float:
    return difflib.SequenceMatcher(None, normalize_text(a), normalize_text(b)).ratio()

def parse_year_range_from_model_label(model_label: str):
    # ×ª×•××š ×’× ×‘"1962-2012, 2023-2025" â€“ × ×™×§×— ××ª ×”×˜×•×•×— ×”×¨××©×•×Ÿ
    m = re.search(r"\((\d{4})\s*-\s*(\d{4})", model_label)
    if m:
        try:
            return int(m.group(1)), int(m.group(2))
        except:
            return None, None
    return None, None

# ====== ×“×™×‘××’ ×—×™×‘×•×¨ â€“ ××•×¦×’ ×ª××™×“ ======
def _ok(step):    return {"step": step, "status": "âœ… OK", "hint": ""}
def _fail(step, why, fix): return {"step": step, "status": f"âŒ FAIL - {why}", "hint": fix}

def run_connectivity_diagnostics():
    results = []

    # 1) ×‘×“×™×§×ª ×§×™×•× ×¡×™×§×¨×˜×™×
    if GEMINI_API_KEY:
        results.append(_ok("GEMINI_API_KEY × ××¦×"))
    else:
        results.append(_fail("GEMINI_API_KEY", "×—×¡×¨", "×™×© ×œ×©×™× ××¤×ª×— ×‘Ö¾Secrets ×‘×©× GEMINI_API_KEY"))
    if GOOGLE_SHEET_ID:
        results.append(_ok("GOOGLE_SHEET_ID × ××¦×"))
    else:
        results.append(_fail(
            "GOOGLE_SHEET_ID", "×—×¡×¨",
            "×”×¢×ª×§ ××ª ×”-ID ××”Ö¾URL ×©×œ ×”×’×™×œ×™×•×Ÿ (×”×—×œ×§ ×©×‘×™×Ÿ /d/ ×œ-/edit) ×•×©××•×¨ ×‘-Secrets."
        ))
    if GOOGLE_SERVICE_ACCOUNT_JSON:
        results.append(_ok("GOOGLE_SERVICE_ACCOUNT_JSON × ××¦×"))
    else:
        results.append(_fail(
            "GOOGLE_SERVICE_ACCOUNT_JSON", "×—×¡×¨",
            "×”×“×‘×§ ××ª ×§×•×‘×¥ ×”Ö¾Service Account JSON ×›×•×œ×• ×‘×™×Ÿ ×©×œ×•×©×” ××¨×›××•×ª ××©×•×œ×©×•×ª ×‘-Secrets."
        ))
        return results, None, None, None  # ××™×Ÿ ×˜×¢× ×œ×”××©×™×š

    # 2) JSON ×©×œ Service Account
    try:
        service_info = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
        results.append(_ok("×¤×¨×¡×™× ×’ JSON ×©×œ Service Account"))
    except Exception as e:
        results.append(_fail(
            "×¤×¨×¡×™× ×’ JSON ×©×œ Service Account", "JSON ×œ× ×ª×§×™×Ÿ",
            f"×•×“× ×©×”×˜×§×¡×˜ ×‘Ö¾Secrets ×”×•× JSON ××œ× (×œ× TOML). ×©×’×™××”:\n{repr(e)}"
        ))
        return results, None, None, None

    # ×ª×™×§×•×Ÿ ××•×˜×•××˜×™ ×œ×©×‘×™×¨×•×ª ××¤×ª×— ×¢× \\n
    try:
        if "private_key" in service_info and "\\n" in service_info["private_key"]:
            service_info["private_key"] = service_info["private_key"].replace("\\n", "\n")
    except Exception:
        pass

    # 3) ××¤×ª×—×•×ª ×—×•×‘×” ×§×™×™××™×
    required_keys = ["type","project_id","private_key_id","private_key","client_email","client_id","token_uri"]
    missing = [k for k in required_keys if k not in service_info]
    if missing:
        results.append(_fail(
            "×‘×“×™×§×ª ×©×“×•×ª ×—×•×‘×” ×‘-JSON", f"×—×¡×¨×™×: {', '.join(missing)}",
            "×™×™×¦× ××—×“×© ××ª ×”××¤×ª×— ×‘Ö¾GCP (IAM & Admin â†’ Service Accounts â†’ Keys â†’ Add Key â†’ Create new key (JSON))."
        ))
        return results, None, None, None
    else:
        results.append(_ok("×©×“×•×ª ×—×•×‘×” ×§×™×™××™× ×‘-JSON"))

    # 4) ×™×¦×™×¨×ª Credentials
    try:
        from google.oauth2.service_account import Credentials
        credentials = Credentials.from_service_account_info(
            service_info, scopes=["https://www.googleapis.com/auth/spreadsheets"]
        )
        results.append(_ok("×™×¦×™×¨×ª Credentials ××”Ö¾JSON"))
    except Exception as e:
        results.append(_fail(
            "×™×¦×™×¨×ª Credentials", "× ×›×©×œ",
            f"×‘×“×•×§ ××ª private_key ×•×©×”×•× ×›×•×œ×œ BEGIN/END. ×©×’×™××”:\n{repr(e)}"
        ))
        return results, None, None, None

    # 5) ×”×ª×—×‘×¨×•×ª gspread
    try:
        import gspread
        gc = gspread.authorize(credentials)
        results.append(_ok("××™××•×ª gspread"))
    except Exception as e:
        results.append(_fail(
            "authorize(gspread)", "× ×›×©×œ",
            f"×•×“× ×©×”Ö¾scope × ×›×•×Ÿ ×•×©×œ× ×—×¡×•××•×ª ×”×¨×©××•×ª. ×©×’×™××”:\n{repr(e)}"
        ))
        return results, None, None, None

    # 6) ×¤×ª×™×—×ª ×”×’×™×œ×™×•×Ÿ ×œ×¤×™ ID
    try:
        sh = gc.open_by_key(GOOGLE_SHEET_ID)
        results.append(_ok(f"×¤×ª×™×—×ª ×’×™×œ×™×•×Ÿ ×œ×¤×™ ID ({GOOGLE_SHEET_ID})"))
    except Exception as e:
        results.append(_fail(
            "×¤×ª×™×—×ª ×’×™×œ×™×•×Ÿ ×œ×¤×™ ID", "× ×›×©×œ",
            "×©×ª×£ ××ª ×”×’×™×œ×™×•×Ÿ ×¢× ×›×ª×•×‘×ª ×”Ö¾client_email ×©×‘Ö¾Service Account (Viewer/Editor). "
            f"client_email: {service_info.get('client_email','(×œ× ×™×“×•×¢)')}\n"
            f"×©×’×™××”: {repr(e)}"
        ))
        return results, None, None, None

    # 7) worksheet ×¨××©×•×Ÿ
    try:
        ws = sh.sheet1
        results.append(_ok("×’×™×©×” ×œÖ¾sheet1"))
    except Exception as e:
        results.append(_fail(
            "×’×™×©×” ×œÖ¾sheet1", "× ×›×©×œ",
            f"×•×“× ×©×§×™×™× worksheet ×¨××©×•×Ÿ. ×©×’×™××”:\n{repr(e)}"
        ))
        return results, sh, None, None

    # 8) ×›×•×ª×¨×•×ª ×—×•×‘×”
    try:
        headers = [
            "date","user_id","make","model","year","fuel","transmission",
            "base_score","avg_cost","issues","search_performed"
        ]
        current = ws.row_values(1)
        if [h.lower() for h in current] != headers:
            ws.update("A1", [headers])
        results.append(_ok("×•×™×“×•× ×›×•×ª×¨×•×ª ×‘×’×™×œ×™×•×Ÿ"))
    except Exception as e:
        results.append(_fail(
            "×¢×“×›×•×Ÿ ×›×•×ª×¨×•×ª ×‘×’×™×œ×™×•×Ÿ", "× ×›×©×œ",
            f"×‘×“×•×§ ×”×¨×©××•×ª ×¢×¨×™×›×” (Editor) ×œ×©×™×¨×•×ª. ×©×’×™××”:\n{repr(e)}"
        ))
        # ×¢×“×™×™×Ÿ × ×—×–×™×¨ ××ª ws ×œ×”××©×š × ×™×¡×•×™
        return results, sh, ws, gc

    return results, sh, ws, gc

# ====== ××¨×™×¦×™× ×“×™××’× ×•×¡×˜×™×§×” ×ª××™×“ ×•××¦×™×’×™× ======
diag_results, sh, ws, gc = run_connectivity_diagnostics()
st.markdown("### ğŸ§ª ×“×™××’× ×•×¡×˜×™×§×” ×œ×—×™×‘×•×¨ Google Sheets (××•×¦×’ ×ª××™×“)")
for r in diag_results:
    st.markdown(f"- **{r['step']}** â†’ {r['status']}")
    if r["hint"]:
        with st.expander("××™×š ×œ×ª×§×Ÿ / ×”×¡×‘×¨", expanded=False):
            st.write(r["hint"])

# ×× ××™×Ÿ ×—×™×‘×•×¨ ×©××™×© ×œÖ¾ws â€“ ××™×Ÿ ×˜×¢× ×œ×”××©×™×š
if ws is None:
    st.error("âŒ ××™×Ÿ ×—×™×‘×•×¨ ×©××™×© ×œÖ¾Google Sheets. ×ª×§×Ÿ ×œ×¤×™ ×”×”× ×—×™×•×ª ×œ××¢×œ×” ×•×¨×¢× ×Ÿ.")
    st.stop()

# ====== I/O ××•×œ ×”×’×™×œ×™×•×Ÿ ======
def sheet_to_df() -> pd.DataFrame:
    try:
        recs = ws.get_all_records()
    except Exception as e:
        st.error("âŒ ×›×©×œ ×‘×§×¨×™××ª × ×ª×•× ×™× ××”×’×™×œ×™×•×Ÿ")
        st.code(repr(e))
        return pd.DataFrame(columns=[
            "date","user_id","make","model","year","fuel","transmission",
            "base_score","avg_cost","issues","search_performed"
        ])

    if not recs:
        return pd.DataFrame(columns=[
            "date","user_id","make","model","year","fuel","transmission",
            "base_score","avg_cost","issues","search_performed"
        ])

    df = pd.DataFrame(recs)
    # ×˜×™×¤×•×¡×™×
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
    for c in ["make","model","fuel","transmission","issues","user_id","search_performed"]:
        if c in df.columns:
            df[c] = df[c].astype(str).fillna("")
    if "year" in df.columns:
        df["year"] = pd.to_numeric(df["year"], errors="coerce").fillna(0).astype(int)
    if "base_score" in df.columns:
        df["base_score"] = pd.to_numeric(df["base_score"], errors="coerce")
    if "avg_cost" in df.columns:
        df["avg_cost"] = pd.to_numeric(df["avg_cost"], errors="coerce")
    return df

def append_row_to_sheet(row_dict: dict):
    order = ["date","user_id","make","model","year","fuel","transmission",
             "base_score","avg_cost","issues","search_performed"]
    row = [row_dict.get(k,"") for k in order]
    try:
        ws.append_row(row, value_input_option="USER_ENTERED")
    except Exception as e:
        st.error("âŒ ×›×©×œ ×‘×›×ª×™×‘×” ×œ×©×™×˜×¡")
        st.code(repr(e))

# ====== ××’×‘×œ×•×ª ×©×™××•×© ======
GLOBAL_DAILY_LIMIT = 1000
USER_DAILY_LIMIT = 0   # ×œ×¤×™ ×‘×§×©×ª×š: 0 = ×œ×œ× ××’×‘×œ×ª ××©×ª××© (×›×•×œ× anonymous)

def within_daily_global_limit(df: pd.DataFrame, limit=GLOBAL_DAILY_LIMIT):
    today = pd.Timestamp.now().date()
    df_today = df[df["date"].dt.date == today] if "date" in df.columns else pd.DataFrame()
    return (len(df_today) < limit, len(df_today))

def within_daily_user_limit(df: pd.DataFrame, user_id: str, limit=USER_DAILY_LIMIT):
    if limit <= 0:
        return True, 0
    today = pd.Timestamp.now().date()
    user_today = df[(df["user_id"].str.lower()==str(user_id).lower()) & (df["date"].dt.date == today)] if "date" in df.columns else pd.DataFrame()
    return (len(user_today) < limit, len(user_today))

# ====== Cache ×—×›×: ×× ×™×© ×œ×¤×—×•×ª ××—×ª ×‘-45 ×™××™× â†’ ××—×–×™×¨×™×; ×× 3+ â†’ ×××•×¦×¢ ======
def get_cached_from_sheet(make: str, model: str, year: int, max_days=45):
    df = sheet_to_df()
    if df.empty:
        return None, df

    cutoff = pd.Timestamp.now() - pd.Timedelta(days=max_days)
    recent = df[df["date"] >= cutoff]

    make_clean = normalize_text(make)
    model_clean = normalize_text(model)

    # ×”×ª×××” ×—×–×§×” ×ª×—×™×œ×” (>=0.95), ×•××– ×¨×›×” (>=0.90)
    hits = pd.DataFrame()
    for th in [0.95, 0.90]:
        cand = recent[
            (recent["year"] == int(year)) &
            (recent["make"].apply(lambda x: similar(x, make_clean) >= th)) &
            (recent["model"].apply(lambda x: similar(x, model_clean) >= th))
        ]
        if not cand.empty:
            hits = cand.sort_values("date")
            break

    if hits.empty:
        return None, df

    # ×× ×™×© 3+ ×ª×•×¦××•×ª â†’ × ×—×–×™×¨ ×××•×¦×¢ (×œ×™×¦×™×‘×•×ª)
    if len(hits) >= 3:
        avg_score = float(hits["base_score"].dropna().mean()) if "base_score" in hits else None
        avg_cost  = float(hits["avg_cost"].dropna().mean()) if "avg_cost" in hits else None
        issues_agg = "; ".join([str(x) for x in hits["issues"].astype(str).tail(3)])  # ××—×¨×•× ×•×ª ×œ×ª×¦×•×’×”
        return {
            "is_aggregate": True,
            "count": len(hits),
            "base_score": round(avg_score) if avg_score is not None else None,
            "avg_cost": round(avg_cost) if avg_cost is not None else None,
            "issues": issues_agg,
            "search_performed": "true (history aggregate)",
            "last_date": hits.iloc[-1]["date"]
        }, df

    # ××—×¨×ª × ×—×–×™×¨ ××ª ×”×¢×“×›× ×™×ª ×‘×™×•×ª×¨
    row = hits.iloc[-1].to_dict()
    row["is_aggregate"] = False
    row["count"] = len(hits)
    return row, df

# ====== UI ×‘×—×™×¨×” ======
st.markdown("### ğŸ” ×‘×—×™×¨×ª ×™×¦×¨×Ÿ, ×“×’× ×•×©× ×ª×•×Ÿ")
make_list = sorted(israeli_car_market_full_compilation.keys())
make_choice = st.selectbox("×‘×—×¨ ×™×¦×¨×Ÿ ××”×¨×©×™××”:", ["×‘×—×¨..."] + make_list, index=0)
make_input  = st.text_input("××• ×”×–×Ÿ ×©× ×™×¦×¨×Ÿ ×™×“× ×™×ª:")

if make_choice != "×‘×—×¨...":
    selected_make = make_choice
elif make_input.strip():
    selected_make = make_input.strip()
else:
    selected_make = ""

selected_model = ""
year_range = None

if selected_make in israeli_car_market_full_compilation:
    models = israeli_car_market_full_compilation[selected_make]
    model_choice = st.selectbox(f"×‘×—×¨ ×“×’× ×©×œ {selected_make}:", ["×‘×—×¨ ×“×’×..."] + models, index=0)
    model_input  = st.text_input("××• ×”×–×Ÿ ×“×’× ×™×“× ×™×ª:")
    if model_choice != "×‘×—×¨ ×“×’×...":
        selected_model = model_choice
    elif model_input.strip():
        selected_model = model_input.strip()

    if selected_model:
        yr_start, yr_end = parse_year_range_from_model_label(selected_model)
        if yr_start and yr_end:
            year_range = (yr_start, yr_end)
else:
    if selected_make:
        st.warning("ï¸ğŸ“‹ ×™×¦×¨×Ÿ ×œ× ×‘××™×œ×•×Ÿ â€“ ×”×–×Ÿ ×“×’× ×™×“× ×™×ª:")
    selected_model = st.text_input("×©× ×“×’×:")

# ×©× ×ª×•×Ÿ
if year_range:
    year = st.number_input(
        f"×©× ×ª ×™×™×¦×•×¨ (×˜×•×•×— ×œ×¤×™ ×”××™×œ×•×Ÿ: {year_range[0]}â€“{year_range[1]}):",
        min_value=year_range[0], max_value=year_range[1], step=1
    )
else:
    year = st.number_input("×©× ×ª ×™×™×¦×•×¨:", min_value=1960, max_value=2025, step=1)

# ×“×œ×§/×ª×™×‘×”
col1, col2 = st.columns(2)
with col1:
    fuel_type = st.selectbox("×¡×•×’ ×“×œ×§:", ["×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™", "×—×©××œ×™", "××—×¨"])
with col2:
    transmission = st.selectbox("×ª×™×‘×ª ×”×™×œ×•×›×™×:", ["××•×˜×•××˜×™×ª", "×™×“× ×™×ª"])

st.markdown("---")

# ====== ×”×¤×¢×œ×” ======
if st.button("×‘×“×•×§ ×××™× ×•×ª"):
    # ×–×™×”×•×™ ××©×ª××©: ×œ×¤×™ ×‘×—×™×¨×ª×š â€“ ×›×•×œ× anonymous
    current_user = "anonymous"

    if not selected_make or not selected_model:
        st.error("×™×© ×œ×”×–×™×Ÿ ×©× ×™×¦×¨×Ÿ ×•×“×’× ×ª×§×™× ×™×.")
        st.stop()

    # ××’×‘×œ×•×ª ×™×•××™×•×ª
    df_all = sheet_to_df()
    ok_global, total_global = within_daily_global_limit(df_all, limit=GLOBAL_DAILY_LIMIT)
    ok_user, total_user     = within_daily_user_limit(df_all, user_id=current_user, limit=USER_DAILY_LIMIT)

    if not ok_global:
        st.error(f"âŒ ×—×¦×™×ª× ××ª ××’×‘×œ×ª {GLOBAL_DAILY_LIMIT} ×”×‘×“×™×§×•×ª ×”×™×•××™×•×ª ×œ×›×œ×œ ×”××¢×¨×›×ª (×›×‘×¨ ×‘×•×¦×¢×• {total_global}). × ×¡×• ××—×¨.")
        st.stop()
    if not ok_user:
        st.error(f"âŒ ×”×’×¢×ª ×œ××›×¡×ª ×”×™×•××™×ª ×œ××©×ª××© ({total_user}/{USER_DAILY_LIMIT}). × ×¡×” ××—×¨.")
        st.stop()

    st.info(f"× ×™×¦×•×œ ×™×•××™ â€“ ××¢×¨×›×ª: {total_global}/{GLOBAL_DAILY_LIMIT} | ×œ××©×ª××©: {'×œ×œ× ××’×‘×œ×”'}")

    st.info(f"×‘×•×“×§ Cache ×‘×©×™×˜×¡ ×¢×‘×•×¨ {selected_make} {selected_model} ({year})...")
    cached_row, df_all_after = get_cached_from_sheet(selected_make, selected_model, int(year), max_days=45)

    # ×× ×§×™×™××ª ××¤×™×œ×• ×ª×•×¦××” ××—×ª ×¢×“×›× ×™×ª â†’ ××¦×™×’×™× ××™×™×“
    if cached_row:
        if cached_row.get("is_aggregate"):
            st.success(f"âœ… × ××¦××• {cached_row['count']} ×ª×•×¦××•×ª ×¢×“×›× ×™×•×ª (â‰¤45 ×™×•×). ××•×¦×’ ×××•×¦×¢ ×™×¦×™×‘. ××™×Ÿ ×¤× ×™×™×” ×œÖ¾Gemini.")
            if cached_row.get("base_score") is not None:
                st.subheader(f"×¦×™×•×Ÿ ×××™× ×•×ª ×›×•×œ×œ (×××•×¦×¢): {int(cached_row['base_score'])}/100")
            if cached_row.get("avg_cost") is not None:
                st.info(f"×¢×œ×•×ª ×ª×—×–×•×§×” ×××•×¦×¢×ª (×××•×¦×¢): ×›Ö¾{int(float(cached_row['avg_cost']))} â‚ª")
            st.write(f"×ª×§×œ×•×ª × ×¤×•×¦×•×ª (×©×œ×•×© ×”××—×¨×•× ×•×ª): {cached_row.get('issues','â€”')}")
            st.write(f"× ××¦× ×‘×××¦×¢×•×ª ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™: {cached_row.get('search_performed','false')}")
            st.stop()
        else:
            st.success("âœ… × ××¦××” ×ª×•×¦××” ×©××•×¨×” ×Ö¾45 ×”×™××™× ×”××—×¨×•× ×™×. ×œ×œ× ×¤× ×™×™×” ×œÖ¾Gemini.")
            st.subheader(f"×¦×™×•×Ÿ ×××™× ×•×ª ×›×•×œ×œ: {int(cached_row.get('base_score',0))}/100")
            if cached_row.get("avg_cost") not in [None, "", "nan"]:
                st.info(f"×¢×œ×•×ª ×ª×—×–×•×§×” ×××•×¦×¢×ª: ×›Ö¾{int(float(cached_row.get('avg_cost',0)))} â‚ª")
            st.write(f"×ª×§×œ×•×ª × ×¤×•×¦×•×ª: {cached_row.get('issues','â€”')}")
            st.write(f"× ××¦× ×‘×××¦×¢×•×ª ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™: {cached_row.get('search_performed','false')}")
            st.stop()

    # ××™×Ÿ Cache â†’ ×¤×•× ×™× ×œ××•×“×œ
    prompt = f"""
    ××ª×” ××•××—×” ×œ×××™× ×•×ª ×¨×›×‘×™× ×‘×™×©×¨××œ ×¢× ×’×™×©×” ×œ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™.
    ×—×•×‘×” ×œ×‘×¦×¢ ×—×™×¤×•×© ×¢×“×›× ×™ ×‘×¢×‘×¨×™×ª ×•×‘×× ×’×œ×™×ª ×××§×•×¨×•×ª ×××™× ×™× ×‘×œ×‘×“.
    ×”×—×–×¨ JSON ×‘×œ×‘×“ ×¢× ×”× ×ª×•× ×™× ×”×‘××™×:
    **You must perform an internet search for information sources for the parameters I requested.**
    **You must perform an internet search for repair prices in Israel and Hebrew sources. You can also search for information about faults from international sources, but repair prices are only from Israel.**

    {{
        "search_performed": true ××• false,
        "base_score": ××¡×¤×¨ ×‘×™×Ÿ 0 ×œ-100,
        "common_issues": [×ª×§×œ×•×ª × ×¤×•×¦×•×ª ×‘×¢×‘×¨×™×ª],
        "avg_repair_cost_ILS": ××¡×¤×¨ ×××•×¦×¢,
        "issues_with_costs": [
            {{"issue": "×©× ×”×ª×§×œ×” ×‘×¢×‘×¨×™×ª", "avg_cost_ILS": ××¡×¤×¨, "source": "××§×•×¨"}}
        ],
        "reliability_summary": "×¡×™×›×•× ×‘×¢×‘×¨×™×ª ×¢×œ ×¨××ª ×”×××™× ×•×ª",
        "sources": ["×¨×©×™××ª ××ª×¨×™×"]
    }}

    ğŸ§® ××©×§×œ×•×ª ×œ×¦×™×•×Ÿ ×××™× ×•×ª:
    - ×× ×•×¢/×’×™×¨ â€“ 35%
    - ×—×©××œ ×•××œ×§×˜×¨×•× ×™×§×” â€“ 20%
    - ××ª×œ×™× ×•×‘×œ××™× â€“ 10%
    - ×¢×œ×•×ª ×ª×—×–×•×§×” â€“ 15%
    - ×©×‘×™×¢×•×ª ×¨×¦×•×Ÿ â€“ 15%
    - ×¨×™×§×•×œ×™× â€“ 5%

    ×¨×›×‘: {selected_make} {selected_model} {int(year)}
    ×¡×•×’ ×“×œ×§: {fuel_type}
    ×ª×™×‘×ª ×”×™×œ×•×›×™×: {transmission}
    ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“.
    """.strip()

    try:
        with st.spinner("××‘×¦×¢ ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™ ×•××—×©×‘ ×¦×™×•×Ÿ..."):
            resp = llm.generate_content(prompt)
            raw = (getattr(resp, "text", "") or "").strip()
            m = re.search(r"\{.*\}", raw, re.DOTALL)
            if m:
                parsed = json.loads(m.group())
            else:
                # × ×™×¡×™×•×Ÿ ×ª×™×§×•×Ÿ JSON "×›××¢×˜ ×ª×§×™×Ÿ"
                fixed = repair_json(raw)
                parsed = json.loads(fixed)

        base_score = int(parsed.get("base_score", 0) or 0)
        issues = parsed.get("common_issues", [])
        avg_cost = parsed.get("avg_repair_cost_ILS", 0)
        search_flag = parsed.get("search_performed", False)
        summary = parsed.get("reliability_summary", "××™×Ÿ ××™×“×¢.")
        detailed_costs = parsed.get("issues_with_costs", [])

        if search_flag:
            st.success("ğŸŒ ×‘×•×¦×¢ ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™ ×‘×–××Ÿ ×××ª.")
        else:
            st.warning("âš ï¸ ×œ× ×‘×•×¦×¢ ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™ â€” ×™×™×ª×›×Ÿ ×©×”××™×“×¢ ×—×œ×§×™.")

        st.subheader(f"×¦×™×•×Ÿ ×××™× ×•×ª ×›×•×œ×œ: {base_score}/100")
        st.write(summary)

        if issues:
            st.markdown("**ğŸ”§ ×ª×§×œ×•×ª × ×¤×•×¦×•×ª:**")
            for i in issues:
                st.markdown(f"- {i}")

        if detailed_costs:
            st.markdown("**ğŸ’° ×¢×œ×•×™×•×ª ×ª×™×§×•×Ÿ (××™× ×“×™×§×˜×™×‘×™):**")
            for item in detailed_costs:
                st.markdown(f"- {item.get('issue','')}: ×›Ö¾{item.get('avg_cost_ILS', 0)} â‚ª (××§×•×¨: {item.get('source','')})")

        # ×©××™×¨×” ×œ×©×™×˜×¡ (×ª××™×“ normalize ×œ×©××•×ª)
        append_row_to_sheet({
            "date": datetime.date.today().isoformat(),
            "user_id": "anonymous",
            "make": normalize_text(selected_make),
            "model": normalize_text(selected_model),
            "year": int(year),
            "fuel": fuel_type,
            "transmission": transmission,
            "base_score": base_score,
            "avg_cost": avg_cost,
            "issues": "; ".join(issues) if isinstance(issues, list) else str(issues),
            "search_performed": str(bool(search_flag)).lower()
        })
        st.info("ğŸ’¾ × ×©××¨ ×œ×©×™×˜×¡ ×‘×”×¦×œ×—×”.")

    except Exception as e:
        st.error("×©×’×™××” ×‘×¢×™×‘×•×“ ×”×‘×§×©×”:")
        st.code(repr(e))
        st.code(traceback.format_exc())
