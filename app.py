# -*- coding: utf-8 -*-
# ===========================================================
# ğŸ‡®ğŸ‡± Car Reliability Analyzer v1.5.0
# ×‘×“×™×§×ª ×××™× ×•×ª ×¨×›×‘ ×œ×¤×™ ×™×¦×¨×Ÿ, ×“×’× ×•×©× ×ª×•×Ÿ
# ×›×•×œ×œ ××™×œ×•×Ÿ ×“×™× ××™, ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™, Cache, ×•×”×’×‘×œ×ª ×‘×§×©×•×ª ×™×•××™×ª
# ===========================================================

import os, json, re, datetime
import pandas as pd
import streamlit as st
from github import Github
from json_repair import repair_json
import google.generativeai as genai

# -----------------------------------------------------------
# ×”×’×“×¨×•×ª ×‘×¡×™×¡×™×•×ª
# -----------------------------------------------------------
st.set_page_config(page_title="ğŸš— Car Reliability Analyzer", page_icon="ğŸ”§", layout="centered")
st.title("ğŸš— Car Reliability Analyzer â€“ ×‘×“×™×§×ª ×××™× ×•×ª ×¨×›×‘ ×‘×™×©×¨××œ")

# -----------------------------------------------------------
# ×˜×¢×™× ×ª ××¤×ª×—×•×ª (Secrets)
# -----------------------------------------------------------
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN")
GITHUB_REPO = st.secrets.get("GITHUB_REPO")

if not GEMINI_API_KEY or not GITHUB_TOKEN or not GITHUB_REPO:
    st.error("âš ï¸ ×—×¡×¨×™× ××¤×ª×—×•×ª Secrets (GEMINI_API_KEY, GITHUB_TOKEN, GITHUB_REPO).")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")

# -----------------------------------------------------------
# ×˜×¢×™× ×ª ××™×œ×•×Ÿ ×™×¦×¨× ×™× ×•×“×’××™×
# -----------------------------------------------------------
from car_models_dict import israeli_car_market_full_compilation

# -----------------------------------------------------------
# GitHub ×”×’×“×¨×•×ª
# -----------------------------------------------------------
g = Github(GITHUB_TOKEN)
repo = g.get_repo(GITHUB_REPO)
csv_path = "reliability_results.csv"

# -----------------------------------------------------------
# ×¤×•× ×§×¦×™×” ×œ×‘×“×•×§ cache ×©×œ ×—×™×¤×•×©×™× ×§×•×“××™× (45 ×™×•×)
# -----------------------------------------------------------
def get_cached(make, model, year):
    try:
        contents = repo.get_contents(csv_path)
        df = pd.read_csv(contents.download_url)

        for col in ["make", "model"]:
            df[col] = df[col].astype(str).fillna("").str.strip()
        df["year"] = pd.to_numeric(df["year"], errors="coerce").fillna(0).astype(int)
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

        cutoff_date = pd.Timestamp.now() - pd.Timedelta(days=45)
        recent_df = df[df["date"] >= cutoff_date]

        match = recent_df[
            (recent_df["make"].str.lower() == make.lower()) &
            (recent_df["model"].str.lower() == model.lower()) &
            (recent_df["year"] == int(year))
        ]

        if not match.empty:
            return match.iloc[-1].to_dict()
        return None
    except Exception:
        return None

# -----------------------------------------------------------
# ×¤×•× ×§×¦×™×” ×œ×©××™×¨×” ×œÖ¾GitHub (CSV)
# -----------------------------------------------------------
def append_to_github_csv(user_id, make, model_name, year, base_score, avg_cost, issues, search_performed):
    try:
        try:
            contents = repo.get_contents(csv_path)
            df = pd.read_csv(contents.download_url)
        except Exception:
            df = pd.DataFrame()

        required_cols = ["date", "user_id", "make", "model", "year", "base_score", "avg_cost", "issues", "search_performed"]
        for col in required_cols:
            if col not in df.columns:
                df[col] = ""
        df = df[required_cols]

        new_entry = {
            "date": datetime.date.today().isoformat(),
            "user_id": user_id,
            "make": make,
            "model": model_name,
            "year": year,
            "base_score": base_score,
            "avg_cost": avg_cost,
            "issues": "; ".join(issues) if isinstance(issues, list) else str(issues),
            "search_performed": search_performed
        }

        df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)
        csv_data = df.to_csv(index=False)

        try:
            repo.update_file(csv_path, "update reliability results", csv_data, contents.sha)
        except Exception:
            repo.create_file(csv_path, "create reliability results", csv_data)

    except Exception as e:
        st.warning(f"âš ï¸ ×œ× × ×™×ª×Ÿ ×œ×©××•×¨ ×œÖ¾GitHub: {e}")

# -----------------------------------------------------------
# ×¤×•× ×§×¦×™×™×ª ×‘×“×™×§×ª ××’×‘×œ×ª ×‘×§×©×•×ª ×™×•××™×ª
# -----------------------------------------------------------
def check_daily_limit():
    try:
        contents = repo.get_contents(csv_path)
        df = pd.read_csv(contents.download_url)
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        today = pd.Timestamp.now().date()
        today_df = df[df["date"].dt.date == today]
        total_today = len(today_df)

        if total_today >= 1000:
            return False, total_today
        return True, total_today
    except Exception:
        return True, 0  # ×× ××™×Ÿ ×§×•×‘×¥ ×¢×“×™×™×Ÿ â€“ ×œ× ×œ×—×¡×•×

# -----------------------------------------------------------
# ×××©×§ ×‘×—×™×¨×ª ×™×¦×¨×Ÿ/×“×’× â€“ ×›×•×œ×œ ×”×§×œ×“×” ×—×•×¤×©×™×ª
# -----------------------------------------------------------
make_list = sorted(israeli_car_market_full_compilation.keys())
st.markdown("### ğŸ” ×‘×—×¨ ×™×¦×¨×Ÿ ×•×“×’× ×œ×‘×“×™×§×”")

make_input = st.text_input("×”×§×œ×“ ×™×¦×¨×Ÿ (××• ×‘×—×¨ ××”×¨×©×™××”):")
make_choice = st.selectbox("××• ×‘×—×¨ ×™×¦×¨×Ÿ ××”×¨×©×™××”:", ["×‘×—×¨..."] + make_list)
selected_make = make_input.strip() if make_input else (make_choice if make_choice != "×‘×—×¨..." else "")
selected_model = ""

if selected_make in israeli_car_market_full_compilation:
    models = israeli_car_market_full_compilation[selected_make]
    model_input = st.text_input(f"××• ×”×§×œ×“ ×“×’× ×©×œ {selected_make}:")
    model_choice = st.selectbox(f"××• ×‘×—×¨ ×“×’× ×©×œ {selected_make}:", ["×‘×—×¨ ×“×’×..."] + models)
    selected_model = model_input.strip() if model_input else (model_choice if model_choice != "×‘×—×¨ ×“×’×..." else "")
else:
    st.warning("×©× ×”×—×‘×¨×” ×œ× ××•×¤×™×¢ ×‘××¢×¨×›×ª. ×™×© ×œ×”×–×™×Ÿ ×™×“× ×™×ª:")
    selected_make = st.text_input("×©× ×—×‘×¨×”:")
    selected_model = st.text_input("×©× ×“×’×:")

year = st.number_input("×©× ×ª ×™×™×¦×•×¨:", min_value=2000, max_value=2025, step=1)

# -----------------------------------------------------------
# ×”×¤×¢×œ×ª ×‘×“×™×§×”
# -----------------------------------------------------------
if st.button("×‘×“×•×§ ×××™× ×•×ª"):
    if not selected_make or not selected_model:
        st.error("×™×© ×œ×”×–×™×Ÿ ×©× ×—×‘×¨×” ×•×“×’× ×ª×§×™× ×™×.")
        st.stop()

    # ×‘×“×™×§×ª ××’×‘×œ×ª ×©×™××•×©
    ok, total_today = check_daily_limit()
    if not ok:
        st.error(f"âŒ ×—×¦×™×ª ××ª ××’×‘×œ×ª 1000 ×”×‘×“×™×§×•×ª ×”×™×•××™×•×ª (×›×‘×¨ ×‘×•×¦×¢×• {total_today}). × ×¡×” ×©×•×‘ ××—×¨.")
        st.stop()
    else:
        st.info(f"× ×™×¦×œ×• {total_today}/1000 ×‘×§×©×•×ª ×œ×”×™×•×.")

    user_id = st.session_state.get("user_id", "anonymous")
    st.info(f"××ª×‘×¦×¢×ª ×‘×“×™×§×ª ×××™× ×•×ª ×¢×‘×•×¨ {selected_make} {selected_model} ({year})...")

    cached_row = get_cached(selected_make, selected_model, year)
    if cached_row:
        st.success("âœ… × ××¦××” ×ª×•×¦××” ×©××•×¨×” ×Ö¾45 ×”×™××™× ×”××—×¨×•× ×™×.")
        st.subheader(f"×¦×™×•×Ÿ ×××™× ×•×ª ×›×•×œ×œ: {cached_row['base_score']}/100")
        st.info(f"×¢×œ×•×ª ×ª×—×–×•×§×” ×××•×¦×¢×ª: ×›Ö¾{cached_row['avg_cost']} â‚ª")
        st.write(f"×ª×§×œ×•×ª × ×¤×•×¦×•×ª: {cached_row['issues']}")
        st.write(f"× ××¦× ×‘×××¦×¢×•×ª ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™: {cached_row['search_performed']}")
        st.stop()

    prompt = f"""
    ××ª×” ××•××—×” ×œ×××™× ×•×ª ×¨×›×‘×™× ×‘×™×©×¨××œ ×¢× ×’×™×©×” ×œ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™.
    ×—×•×‘×” ×œ×‘×¦×¢ ×—×™×¤×•×© ×¢×“×›× ×™ ×‘×¢×‘×¨×™×ª ×•×‘×× ×’×œ×™×ª ×××§×•×¨×•×ª ×××™× ×™× ×‘×œ×‘×“.
    ×”×—×–×¨ JSON ×‘×œ×‘×“ ×¢× ×”× ×ª×•× ×™× ×”×‘××™×:
   **You must perform an internet search for information sources for the parameters I requested.**

    {{
        "search_performed": true ××• false,
        "base_score": ××¡×¤×¨ ×‘×™×Ÿ 0 ×œ-100,
        "common_issues": [×ª×§×œ×•×ª × ×¤×•×¦×•×ª ×‘×¢×‘×¨×™×ª],
        "avg_repair_cost_ILS": ××¡×¤×¨ ×××•×¦×¢,
        "issues_with_costs": [
            {{"issue": "×©× ×”×ª×§×œ×” ×‘×¢×‘×¨×™×ª", "avg_cost_ILS": ××¡×¤×¨, "source": "××§×•×¨"}}
        ],
        "reliability_summary": "×¡×™×›×•× ×‘×¢×‘×¨×™×ª ×¢×œ ×¨××ª ×”×××™× ×•×ª",
        "sources": ["×¨×©×™××ª ××ª×¨×™×"]
    }}

    ğŸ§® ××©×§×œ×•×ª ×œ×¦×™×•×Ÿ ×××™× ×•×ª:
    - ×× ×•×¢/×’×™×¨ â€“ 35%
    - ×—×©××œ ×•××œ×§×˜×¨×•× ×™×§×” â€“ 20%
    - ××ª×œ×™× ×•×‘×œ××™× â€“ 10%
    - ×¢×œ×•×ª ×ª×—×–×•×§×” â€“ 15%
    - ×©×‘×™×¢×•×ª ×¨×¦×•×Ÿ â€“ 15%
    - ×¨×™×§×•×œ×™× â€“ 5%

    ×¨×›×‘: {selected_make} {selected_model} {year}
    ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“.
    """

    try:
        response = model.generate_content(prompt)
        text = response.text.strip()
        json_text = re.search(r"\{.*\}", text, re.DOTALL).group()
        parsed = json.loads(json_text)

        base_score = parsed.get("base_score", 0)
        issues = parsed.get("common_issues", [])
        avg_cost = parsed.get("avg_repair_cost_ILS", 0)
        search_flag = parsed.get("search_performed", False)
        summary = parsed.get("reliability_summary", "××™×Ÿ ××™×“×¢.")
        detailed_costs = parsed.get("issues_with_costs", [])

        if search_flag:
            st.success("ğŸŒ ×‘×•×¦×¢ ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™ ×‘×–××Ÿ ×××ª.")
        else:
            st.warning("âš ï¸ ×œ× ×‘×•×¦×¢ ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™ â€” ×™×™×ª×›×Ÿ ×©×”××™×“×¢ ×—×œ×§×™.")

        st.subheader(f"×¦×™×•×Ÿ ×××™× ×•×ª ×›×•×œ×œ: {base_score}/100")
        st.write(summary)

        if issues:
            st.markdown("**ğŸ”§ ×ª×§×œ×•×ª × ×¤×•×¦×•×ª:**")
            for i in issues:
                st.markdown(f"- {i}")

        if detailed_costs:
            st.markdown("**ğŸ’° ×¢×œ×•×™×•×ª ×ª×™×§×•×Ÿ:**")
            for item in detailed_costs:
                st.markdown(f"- {item.get('issue', '')}: ×›Ö¾{item.get('avg_cost_ILS', 0)} â‚ª (××§×•×¨: {item.get('source', '')})")

        append_to_github_csv(user_id, selected_make, selected_model, year, base_score, avg_cost, issues, search_flag)

        if selected_make not in israeli_car_market_full_compilation:
            israeli_car_market_full_compilation[selected_make] = [selected_model]
        elif selected_model not in israeli_car_market_full_compilation[selected_make]:
            israeli_car_market_full_compilation[selected_make].append(selected_model)

        dict_file = "car_models_dict.py"
        content = "israeli_car_market_full_compilation = " + json.dumps(israeli_car_market_full_compilation, ensure_ascii=False, indent=4)
        try:
            existing = repo.get_contents(dict_file)
            repo.update_file(dict_file, "auto-update car models", content, existing.sha)
        except Exception:
            repo.create_file(dict_file, "create car models dict", content)

        st.info("ğŸ“ ×”××™×œ×•×Ÿ ×¢×•×“×›×Ÿ ×‘×”×¦×œ×—×” ×‘Ö¾GitHub.")

    except Exception as e:
        st.error(f"×©×’×™××” ×‘×¢×™×‘×•×“ ×”×‘×§×©×”: {e}")
